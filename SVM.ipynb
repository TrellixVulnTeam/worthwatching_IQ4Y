{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sjhat\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  ipython-dev@scipy.org\"\"\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('clean_data.csv', sep='\\t')\n",
    "data = data[['Date','HGS','HGA','HYC','HRC','HWW','AGS','AGA','AYC','ARC','AWW','watch']]\n",
    "data = data.reindex(index=data.index[::-1])\n",
    "data.reset_index(inplace=True)\n",
    "data['Date'] =  pd.to_datetime(data['Date'])\n",
    "data[['HGS','HGA','HYC',\n",
    "      'HRC','HWW','AGS',\n",
    "      'AGA','AYC','ARC',\n",
    "      'AWW','watch']] = data[['HGS','HGA',\n",
    "                              'HYC','HRC',\n",
    "                              'HWW','AGS',\n",
    "                              'AGA','AYC',\n",
    "                              'ARC','AWW',\n",
    "                              'watch']].apply(pd.to_numeric)\n",
    "data.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>HGS</th>\n",
       "      <th>HGA</th>\n",
       "      <th>HYC</th>\n",
       "      <th>HRC</th>\n",
       "      <th>HWW</th>\n",
       "      <th>AGS</th>\n",
       "      <th>AGA</th>\n",
       "      <th>AYC</th>\n",
       "      <th>ARC</th>\n",
       "      <th>AWW</th>\n",
       "      <th>watch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-13</td>\n",
       "      <td>1.864865</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>1.297297</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>1.405405</td>\n",
       "      <td>1.486486</td>\n",
       "      <td>1.351351</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-05-13</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>1.459459</td>\n",
       "      <td>1.351351</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>1.810811</td>\n",
       "      <td>1.621622</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-05-13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.486486</td>\n",
       "      <td>1.621622</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>2.837838</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>1.540541</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-13</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>1.270270</td>\n",
       "      <td>1.405405</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>1.675676</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-13</td>\n",
       "      <td>1.810811</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>1.621622</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>1.189189</td>\n",
       "      <td>1.702703</td>\n",
       "      <td>1.702703</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-05-13</td>\n",
       "      <td>2.162162</td>\n",
       "      <td>1.027027</td>\n",
       "      <td>1.189189</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>1.351351</td>\n",
       "      <td>1.459459</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-05-13</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>1.540541</td>\n",
       "      <td>1.621622</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>1.972973</td>\n",
       "      <td>1.378378</td>\n",
       "      <td>1.540541</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-05-13</td>\n",
       "      <td>1.162162</td>\n",
       "      <td>1.486486</td>\n",
       "      <td>1.864865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>1.459459</td>\n",
       "      <td>1.864865</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-05-13</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.756757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>1.162162</td>\n",
       "      <td>1.621622</td>\n",
       "      <td>1.486486</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-05-10</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.861111</td>\n",
       "      <td>1.972222</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>1.861111</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.638889</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       HGS       HGA       HYC       HRC       HWW       AGS  \\\n",
       "0 2018-05-13  1.864865  0.864865  1.297297  0.054054  0.297297  1.405405   \n",
       "1 2018-05-13  0.729730  1.459459  1.351351  0.027027  0.216216  0.891892   \n",
       "2 2018-05-13  1.000000  1.486486  1.621622  0.054054  0.270270  2.837838   \n",
       "3 2018-05-13  0.972973  1.270270  1.405405  0.054054  0.216216  1.675676   \n",
       "4 2018-05-13  1.810811  0.756757  1.621622  0.027027  0.324324  1.189189   \n",
       "5 2018-05-13  2.162162  1.027027  1.189189  0.027027  0.405405  0.918919   \n",
       "6 2018-05-13  0.756757  1.540541  1.621622  0.081081  0.189189  1.972973   \n",
       "7 2018-05-13  1.162162  1.486486  1.864865  0.000000  0.324324  0.837838   \n",
       "8 2018-05-13  0.945946  1.000000  1.756757  0.000000  0.081081  1.162162   \n",
       "9 2018-05-10  1.250000  1.861111  1.972222  0.055556  0.388889  1.861111   \n",
       "\n",
       "        AGA       AYC       ARC       AWW  watch  \n",
       "0  1.486486  1.351351  0.135135  0.270270      1  \n",
       "1  1.810811  1.621622  0.027027  0.216216      0  \n",
       "2  0.729730  1.540541  0.054054  0.513514      0  \n",
       "3  0.945946  1.081081  0.108108  0.324324      0  \n",
       "4  1.702703  1.702703  0.108108  0.324324      0  \n",
       "5  1.351351  1.459459  0.054054  0.243243      1  \n",
       "6  1.378378  1.540541  0.054054  0.432432      0  \n",
       "7  1.459459  1.864865  0.027027  0.243243      0  \n",
       "8  1.621622  1.486486  0.027027  0.324324      0  \n",
       "9  0.777778  1.638889  0.027778  0.333333      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recent = data[data['Date'] > '2010-08-01']\n",
    "recent = data[data['Date'] < '2018-05-13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = recent[['HGS','HGA','HYC',\n",
    "      'HRC','HWW','AGS',\n",
    "      'AGA','AYC','ARC',\n",
    "      'AWW']]\n",
    "y = recent['watch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below the data is split into training, validation and testing. Sklearn's train_test_split can be used twice to partition randomly. We are using the 70-15-15% split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_vt, y_train, y_vt = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(X_vt, y_vt, test_size=0.5, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Various Support Vector Machine Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first try a support vector machine model with up to degree 5 features and a linear decision boundary. The parameter C optimized over values from 0.00001 to 10000 in powers of 10. This parameter C can be thought of as the penalization of misclassification. If C is very high then the classifier will be punished greatly for wrong classifications and will adjust to make as many as possible correct. This can of course, lead to overfitting the data. We will see whether this is the case when using the test set.\n",
    "\n",
    "The standard scaler was used which means that the features were scaled to have mean zero and standard deviation 1. This is very important for SVMs because if there is a great difference in scale then the algorithm to solve can fail.\n",
    "\n",
    "The result we are interested in is if the model predicts a game to be worth watching, the probability that it actually is interesting. This corresponds to $\\frac{TP}{FP + TP}$ from the confusion matrix and is usually referred to as **precision**. \n",
    "\n",
    "However, some models can have a good precision but hardly predict any games to be worth watching. Therefore, we require $TP > 100$.\n",
    "\n",
    "I have decided to suppress warnings about the lack of convergence.\n",
    "\n",
    "The best classifier of this type had $c=0.0001$ and had precision of 39.8%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c=1e-05\n",
      "[[419 181]\n",
      " [222 114]]\n",
      "0.3864406779661017\n",
      "c=0.0001\n",
      "[[452 148]\n",
      " [238  98]]\n",
      "0.3983739837398374\n",
      "c=10\n",
      "[[436 164]\n",
      " [232 104]]\n",
      "0.3880597014925373\n",
      "c=100\n",
      "[[472 128]\n",
      " [263  73]]\n",
      "0.36318407960199006\n",
      "c=1000\n",
      "[[405 195]\n",
      " [239  97]]\n",
      "0.3321917808219178\n",
      "c=10000\n",
      "[[418 182]\n",
      " [239  97]]\n",
      "0.34767025089605735\n",
      "c=100000\n",
      "[[438 162]\n",
      " [240  96]]\n",
      "0.37209302325581395\n"
     ]
    }
   ],
   "source": [
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def linear_svc():\n",
    "    for c in [10**i for i in range(-5, 6)]:\n",
    "        polynomial_svm_clf = Pipeline([\n",
    "            ('poly_features', PolynomialFeatures(degree=5)),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('svm_clf', LinearSVC(C=c, loss='hinge'))\n",
    "        ])\n",
    "\n",
    "        polynomial_svm_clf.fit(X_train, y_train)\n",
    "        preds = polynomial_svm_clf.predict(X_validate)\n",
    "        cf = confusion_matrix(y_validate, preds)\n",
    "        if cf[0][1] > 100:\n",
    "            print(f'c={c}')\n",
    "            print(cf)\n",
    "            print(cf[1][1] / (cf[0][1] + cf[1][1]))\n",
    "linear_svc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next a non-linear kernel was used. After some testing, a degree 7 polynomial for the kernel was found to be beneficial to results but not make the computation time completely unreasonable.\n",
    "\n",
    "You may notice that a polynomial is not being used in the features. This is due to the \"kernel trick\". Thanks to the kernel trick, we can get the same results as adding a polynomial in the features simply by making the kernel polynomial.\n",
    "\n",
    "The kernel is a function which gives a measure of the similarity between any two datapoints.\n",
    "\n",
    "The best result was"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c=1\n",
      "[[494 106]\n",
      " [282  54]]\n",
      "0.3375\n",
      "c=10\n",
      "[[444 156]\n",
      " [234 102]]\n",
      "0.3953488372093023\n",
      "c=100\n",
      "[[418 182]\n",
      " [225 111]]\n",
      "0.378839590443686\n",
      "c=1000\n",
      "[[391 209]\n",
      " [214 122]]\n",
      "0.3685800604229607\n",
      "c=10000\n",
      "[[383 217]\n",
      " [193 143]]\n",
      "0.3972222222222222\n",
      "c=100000\n",
      "[[383 217]\n",
      " [193 143]]\n",
      "0.3972222222222222\n"
     ]
    }
   ],
   "source": [
    "for c in [10**i for i in range(0, 6)]:\n",
    "    poly_kernel_svm_clf = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svm_clf', SVC(kernel='poly', degree=7, coef0=1, C=c))\n",
    "    ])\n",
    "\n",
    "    poly_kernel_svm_clf.fit(X_train, y_train)\n",
    "    preds = poly_kernel_svm_clf.predict(X_validate)\n",
    "    cf = confusion_matrix(y_validate, preds)\n",
    "    if cf[0][1] > 100:\n",
    "        print(f'c={c}')\n",
    "        print(cf)\n",
    "        print(cf[1][1] / (cf[0][1] + cf[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the rbf kernel was used. The Gaussian RBF kernel function is given by:\n",
    "$$\\phi_\\gamma (\\textbf{x}, \\ell) = \\exp(-\\gamma \\| \\textbf{x} - \\ell \\| ^ 2)$$\n",
    "\n",
    "This kernel can handle very complicated decision boundaries.\n",
    "\n",
    "The best result was: a probability of 40.3% with a c=100 and gamma=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c=10, g=1\n",
      "[[486 114]\n",
      " [260  76]]\n",
      "0.4\n",
      "c=100, g=1\n",
      "[[483 117]\n",
      " [257  79]]\n",
      "0.4030612244897959\n",
      "c=1000, g=0.1\n",
      "[[452 148]\n",
      " [237  99]]\n",
      "0.4008097165991903\n",
      "c=1000, g=1\n",
      "[[483 117]\n",
      " [257  79]]\n",
      "0.4030612244897959\n",
      "c=10000, g=0.1\n",
      "[[419 181]\n",
      " [219 117]]\n",
      "0.3926174496644295\n",
      "c=10000, g=1\n",
      "[[483 117]\n",
      " [257  79]]\n",
      "0.4030612244897959\n",
      "c=100000, g=0.1\n",
      "[[399 201]\n",
      " [207 129]]\n",
      "0.39090909090909093\n",
      "c=100000, g=1\n",
      "[[483 117]\n",
      " [257  79]]\n",
      "0.4030612244897959\n"
     ]
    }
   ],
   "source": [
    "for c in [10**i for i in range(1, 6)]:\n",
    "    for g in [10**i for i in range(-1, 6)]:\n",
    "        rbf_kernel_svm_clf = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('svm_clf', SVC(kernel='rbf', gamma=g, C=c))\n",
    "        ])\n",
    "        rbf_kernel_svm_clf.fit(X_train, y_train)\n",
    "        preds = rbf_kernel_svm_clf.predict(X_validate)\n",
    "        cf = confusion_matrix(y_validate, preds)\n",
    "        if cf[0][1] > 100:\n",
    "            print(f'c={c}, g={g}')\n",
    "            print(cf)\n",
    "            print(cf[1][1] / (cf[0][1] + cf[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I tried using the sigmoid kernel:\n",
    "$$\\phi_{r, \\gamma} (\\textbf{x}, \\ell) = \\tanh (\\gamma \\cdot \\textbf{x}^T \\ell + r)$$\n",
    "which has a similar motivation to the sigmoid function from logistic regression.\n",
    "\n",
    "The best result here was: a probability of 39.1% with c=10 and gamma=10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c=10, g=0.1\n",
      "[[403 197]\n",
      " [224 112]]\n",
      "0.36245954692556637\n",
      "c=10, g=1\n",
      "[[412 188]\n",
      " [222 114]]\n",
      "0.37748344370860926\n",
      "c=10, g=10\n",
      "[[413 187]\n",
      " [216 120]]\n",
      "0.39087947882736157\n",
      "c=10, g=100\n",
      "[[407 193]\n",
      " [232 104]]\n",
      "0.3501683501683502\n",
      "c=10, g=1000\n",
      "[[419 181]\n",
      " [239  97]]\n",
      "0.3489208633093525\n",
      "c=10, g=10000\n",
      "[[414 186]\n",
      " [227 109]]\n",
      "0.3694915254237288\n",
      "c=10, g=100000\n",
      "[[417 183]\n",
      " [236 100]]\n",
      "0.35335689045936397\n",
      "c=100, g=0.1\n",
      "[[406 194]\n",
      " [223 113]]\n",
      "0.36807817589576547\n",
      "c=100, g=1\n",
      "[[412 188]\n",
      " [225 111]]\n",
      "0.3712374581939799\n",
      "c=100, g=10\n",
      "[[421 179]\n",
      " [226 110]]\n",
      "0.3806228373702422\n",
      "c=100, g=100\n",
      "[[407 193]\n",
      " [232 104]]\n",
      "0.3501683501683502\n",
      "c=100, g=1000\n",
      "[[420 180]\n",
      " [241  95]]\n",
      "0.34545454545454546\n",
      "c=100, g=10000\n",
      "[[421 179]\n",
      " [238  98]]\n",
      "0.35379061371841153\n",
      "c=100, g=100000\n",
      "[[415 185]\n",
      " [237  99]]\n",
      "0.3485915492957746\n",
      "c=1000, g=0.1\n",
      "[[411 189]\n",
      " [215 121]]\n",
      "0.3903225806451613\n",
      "c=1000, g=1\n",
      "[[411 189]\n",
      " [227 109]]\n",
      "0.36577181208053694\n",
      "c=1000, g=10\n",
      "[[419 181]\n",
      " [224 112]]\n",
      "0.3822525597269625\n",
      "c=1000, g=100\n",
      "[[408 192]\n",
      " [231 105]]\n",
      "0.35353535353535354\n",
      "c=1000, g=1000\n",
      "[[418 182]\n",
      " [239  97]]\n",
      "0.34767025089605735\n",
      "c=1000, g=10000\n",
      "[[417 183]\n",
      " [240  96]]\n",
      "0.34408602150537637\n",
      "c=1000, g=100000\n",
      "[[416 184]\n",
      " [240  96]]\n",
      "0.34285714285714286\n",
      "c=10000, g=0.1\n",
      "[[402 198]\n",
      " [221 115]]\n",
      "0.36741214057507987\n",
      "c=10000, g=1\n",
      "[[410 190]\n",
      " [227 109]]\n",
      "0.36454849498327757\n",
      "c=10000, g=10\n",
      "[[420 180]\n",
      " [225 111]]\n",
      "0.38144329896907214\n",
      "c=10000, g=100\n",
      "[[408 192]\n",
      " [231 105]]\n",
      "0.35353535353535354\n",
      "c=10000, g=1000\n",
      "[[418 182]\n",
      " [239  97]]\n",
      "0.34767025089605735\n",
      "c=10000, g=10000\n",
      "[[416 184]\n",
      " [237  99]]\n",
      "0.3498233215547703\n",
      "c=10000, g=100000\n",
      "[[416 184]\n",
      " [238  98]]\n",
      "0.3475177304964539\n",
      "c=100000, g=0.1\n",
      "[[406 194]\n",
      " [220 116]]\n",
      "0.3741935483870968\n",
      "c=100000, g=1\n",
      "[[409 191]\n",
      " [225 111]]\n",
      "0.3675496688741722\n",
      "c=100000, g=10\n",
      "[[419 181]\n",
      " [223 113]]\n",
      "0.3843537414965986\n",
      "c=100000, g=100\n",
      "[[411 189]\n",
      " [231 105]]\n",
      "0.35714285714285715\n",
      "c=100000, g=1000\n",
      "[[418 182]\n",
      " [239  97]]\n",
      "0.34767025089605735\n",
      "c=100000, g=10000\n",
      "[[413 187]\n",
      " [229 107]]\n",
      "0.36394557823129253\n",
      "c=100000, g=100000\n",
      "[[416 184]\n",
      " [235 101]]\n",
      "0.3543859649122807\n"
     ]
    }
   ],
   "source": [
    "for c in [10**i for i in range(1, 6)]:\n",
    "    for g in [10**i for i in range(-1, 6)]:\n",
    "        rbf_kernel_svm_clf = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('svm_clf', SVC(kernel='sigmoid', gamma=g, C=c))\n",
    "        ])\n",
    "        rbf_kernel_svm_clf.fit(X_train, y_train)\n",
    "        preds = rbf_kernel_svm_clf.predict(X_validate)\n",
    "        cf = confusion_matrix(y_validate, preds)\n",
    "        if cf[0][1] > 100:\n",
    "            print(f'c={c}, g={g}')\n",
    "            print(cf)\n",
    "            print(cf[1][1] / (cf[0][1] + cf[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the best performing model here was with the rbf kernel with parameters c=100 and gamma=1. Let's assess it's test accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[502 130]\n",
      " [239  65]]\n",
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "test_model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm_clf', SVC(kernel='rbf', gamma=1, C=100))\n",
    "])\n",
    "test_model.fit(X_train.append(X_validate), \n",
    "                       y_train.append(y_validate))\n",
    "preds = test_model.predict(X_test)\n",
    "cf = confusion_matrix(y_test, preds)\n",
    "print(cf)\n",
    "print(cf[1][1] / (cf[0][1] + cf[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, a dissapointing result. Only 33.3% accuracy on the test data. 30% of games are worth watching so this is not performing any better than random guessing. Support vector machine classifiers have not performed well on the dataset.\n",
    "\n",
    "This is a classic case of the model overfitting the training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
