{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data and Discarding Some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./clean_data.csv',sep='\\t',encoding='utf-8',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop all the unnecessary columns of the DataFrame. The ones used for prediction will be the statistics related to the current form of the team in the league. These are the ones that will be available in real-life for prediction. Of course the predictor column, 'watch' is kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(labels=['Date','HomeTeam','AwayTeam',\n",
    "                  'FTHG','FTAG','HS','AS','HST',\n",
    "                  'AST','HTHG','HTAG','HF','AF',\n",
    "                  'FTR','HTR','HY','AY','HR',\n",
    "                  'AR','Season','WHH','WHD','WHA'],\n",
    "         inplace=True,\n",
    "         axis=1)\n",
    "# Redorder the columns so we have home statistics, then away statistics\n",
    "# then betting odds and finally the classifier.\n",
    "data = data[['HGS','HGA','HYC','HRC','HWW','AGS','AGA','AYC','ARC','AWW','watch']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HGS</th>\n",
       "      <th>HGA</th>\n",
       "      <th>HYC</th>\n",
       "      <th>HRC</th>\n",
       "      <th>HWW</th>\n",
       "      <th>AGS</th>\n",
       "      <th>AGA</th>\n",
       "      <th>AYC</th>\n",
       "      <th>ARC</th>\n",
       "      <th>AWW</th>\n",
       "      <th>watch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>1.517241</td>\n",
       "      <td>1.517241</td>\n",
       "      <td>1.586207</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.035714</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>1.178571</td>\n",
       "      <td>1.178571</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.478261</td>\n",
       "      <td>1.391304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>1.130435</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5197</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4111</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>1.090909</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>2.090909</td>\n",
       "      <td>1.454545</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           HGS       HGA       HYC       HRC       HWW       AGS       AGA  \\\n",
       "483   1.200000  1.266667  1.466667  0.133333  0.266667  1.571429  1.357143   \n",
       "1912  1.166667  1.200000  1.266667  0.066667  0.366667  1.517241  1.517241   \n",
       "2877  1.500000  1.035714  1.500000  0.035714  0.464286  1.178571  1.178571   \n",
       "1025  0.500000  2.500000  3.500000  0.000000  0.750000  1.000000  2.500000   \n",
       "2056  0.750000  1.875000  1.625000  0.250000  0.500000  0.875000  1.625000   \n",
       "6108  1.000000  1.478261  1.391304  0.000000  0.391304  2.000000  0.913043   \n",
       "5197  0.666667  1.166667  2.500000  0.166667  0.333333  1.000000  1.500000   \n",
       "4111  1.500000  2.000000  1.666667  0.333333  0.500000  1.000000  0.833333   \n",
       "2450  1.090909  0.909091  1.909091  0.000000  0.363636  0.454545  2.090909   \n",
       "5565  0.833333  1.666667  1.666667  0.000000  0.500000  2.666667  1.500000   \n",
       "\n",
       "           AYC       ARC       AWW  watch  \n",
       "483   1.500000  0.142857  0.500000      1  \n",
       "1912  1.586207  0.034483  0.517241      1  \n",
       "2877  1.428571  0.142857  0.464286      1  \n",
       "1025  1.500000  0.000000  0.750000      0  \n",
       "2056  1.125000  0.000000  0.500000      0  \n",
       "6108  1.130435  0.086957  0.478261      0  \n",
       "5197  2.333333  0.000000  0.333333      1  \n",
       "4111  1.666667  0.166667  0.166667      0  \n",
       "2450  1.454545  0.090909  0.363636      1  \n",
       "5565  2.000000  0.000000  0.666667      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to classify a new datapoint based on the previous game statistics in the league and betting odds for the coming game, into worth watching or not watching. The model will be trained on the data from previous seasons. This is a situation where k-Nearest Neighbors is appropriate. The model will take a new data point, and classify it based on the k-nearest datapoints. If the k-nearest have a majority of them as worth watching, them the new one will be classified as also worth watching. This model is going to treat the data as points living in a 13-dimensional space and you can imagine points being colored red if they are worth watching and blue if not.\n",
    "\n",
    "# Implementing the Predictor by Hand\n",
    "\n",
    "Rather than using an implementation of k-Nearest Neighbors from a package like scikit-learn I will implement it using just numpy and pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function normalizes all the columns of a dataframe\n",
    "# to have mean 0 and standard deviation 1. This ensures \n",
    "# that no column has a dominant impact on the model\n",
    "def normalize(df):\n",
    "    return (df - df.mean()) / df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes the dataframe and a newpoint to classify. It returns\n",
    "# a Series object with the distance from each of the rows of the dataframe\n",
    "# to the newpoint. We use Euclidean distance\n",
    "def find_distances(df, newpoint):\n",
    "    assert type(newpoint) == pd.Series, 'The new point must be a pd.Series object'\n",
    "    assert newpoint.shape[0] == (df.shape[1] - 1), f'Your point is the wrong shape, newpoint shape is {newpoint.shape[0]} and df columns  - 1 is {df.shape[1] - 1}'\n",
    "    distances = []\n",
    "    for i, row in df.drop('watch', axis=1).iterrows():\n",
    "        distances.append(np.linalg.norm(row - newpoint))\n",
    "    return pd.Series(distances)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a dataframe, a series of distances (found above)\n",
    "# and a value of k this will return the\n",
    "# k nearest rows of the dataframe\n",
    "def nearest(df, distances, k):\n",
    "    assert type(k) == int, 'k must be an integer'\n",
    "    assert 1 <= k <= df.shape[0], 'k must be a positive integer'\n",
    "    assert type(distances) == pd.Series, 'Distances must be a pd.Series object'\n",
    "    copy = df.copy()\n",
    "    copy['distances'] = distances\n",
    "    return copy.sort_values(by='distances',axis=0)[:k].drop('distances', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a dataframe with k rows will return the majority\n",
    "# ruling on 'watch' variable, in case of a tie it will return\n",
    "# 0 = 'not worth watching'\n",
    "def worth_watching(nearest):\n",
    "    average = nearest['watch'].sum() / nearest['watch'].count()\n",
    "    return int(average > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can put these inside a general predcition funciton\n",
    "def predict(dataframe, newpoint, k=3):\n",
    "    df = normalize(dataframe)\n",
    "    dists = find_distances(df, newpoint)\n",
    "    near = nearest(df, dists, k)\n",
    "    return worth_watching(near)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, watch=1\n",
      "k=2, watch=1\n",
      "k=3, watch=1\n",
      "k=4, watch=1\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "newpoint = pd.Series({'HGS':2.7,'HGA':1.8,'HYC':3,\n",
    "                      'HRC':0.1,'HWW':0.6,'AGS':2,\n",
    "                      'AGA':2.3,'AYC':1.3,'ARC':0.15,\n",
    "                      'AWW':0.7})\n",
    "for k in range(1, 5):\n",
    "    print(f'k={k}, watch={predict(data, newpoint, k)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection and Testing\n",
    "\n",
    "To determine the best choice of k-value for the model we will be splitting the data into training and testing subsets. I will assign 80% to training and 20% to testing. These will be randomly assigned. I will run 10-fold cross validation which means that the training subset will be split into 10 same size non-intersecting subsets. We will fit the model for values of k on 90% of the training data then validate it on the remaining 10%. Once we have done this 10 times we will have an accuracy for that value of k. Once we have done this for all values of k the one with the highest accuracy from 10-fold cross-validation will be selected as the optimal value.\n",
    "\n",
    "Once we have tested all the values of k we will assess the final accuracy of the model by fitting on all the training data and testing on the test data. This process eliminates bias in the final accuracy value.\n",
    "\n",
    "## Subsetting\n",
    "\n",
    "You will notice below that the training fraction is only 10% of the data! This is because the prediction takes a very long time to run. This is due to the fact that when we are classifying a new data point we must calculate distance from this new point to all of the training points. In this kind of implementation there are no ways around it. I am going to use 10% for my own implementation and then we will use a package below for the full 80% training. It will be interesting to see the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2718) # Euler\n",
    "training_frac = 0.1 # Train on over 600 games\n",
    "testing_frac = 0.05 # Test on over 300 games\n",
    "indices_train = random.sample([i for i in range(len(data))], \n",
    "                              math.floor(training_frac * len(data)))\n",
    "indices_test = random.sample([i for i in range(len(data)) if i not in indices_train], \n",
    "                             math.floor(testing_frac * len(data)))\n",
    "data_train = data.iloc[indices_train].reset_index()\n",
    "data_test = data.iloc[indices_test].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the optimal value of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fold done for k=1\n",
      "1 fold done for k=1\n",
      "2 fold done for k=1\n",
      "3 fold done for k=1\n",
      "4 fold done for k=1\n",
      "5 fold done for k=1\n",
      "6 fold done for k=1\n",
      "7 fold done for k=1\n",
      "8 fold done for k=1\n",
      "9 fold done for k=1\n",
      "The validation accuracy for k=1 is 52.244%\n",
      "0 fold done for k=2\n",
      "1 fold done for k=2\n",
      "2 fold done for k=2\n",
      "3 fold done for k=2\n",
      "4 fold done for k=2\n",
      "5 fold done for k=2\n",
      "6 fold done for k=2\n",
      "7 fold done for k=2\n",
      "8 fold done for k=2\n",
      "9 fold done for k=2\n",
      "The validation accuracy for k=2 is 54.167%\n",
      "0 fold done for k=3\n",
      "1 fold done for k=3\n",
      "2 fold done for k=3\n",
      "3 fold done for k=3\n",
      "4 fold done for k=3\n",
      "5 fold done for k=3\n",
      "6 fold done for k=3\n",
      "7 fold done for k=3\n",
      "8 fold done for k=3\n",
      "9 fold done for k=3\n",
      "The validation accuracy for k=3 is 55.609%\n",
      "0 fold done for k=4\n",
      "1 fold done for k=4\n",
      "2 fold done for k=4\n",
      "3 fold done for k=4\n",
      "4 fold done for k=4\n",
      "5 fold done for k=4\n",
      "6 fold done for k=4\n",
      "7 fold done for k=4\n",
      "8 fold done for k=4\n",
      "9 fold done for k=4\n",
      "The validation accuracy for k=4 is 54.327%\n",
      "0 fold done for k=5\n",
      "1 fold done for k=5\n",
      "2 fold done for k=5\n",
      "3 fold done for k=5\n",
      "4 fold done for k=5\n",
      "5 fold done for k=5\n",
      "6 fold done for k=5\n",
      "7 fold done for k=5\n",
      "8 fold done for k=5\n",
      "9 fold done for k=5\n",
      "The validation accuracy for k=5 is 54.487%\n",
      "0 fold done for k=6\n",
      "1 fold done for k=6\n",
      "2 fold done for k=6\n",
      "3 fold done for k=6\n",
      "4 fold done for k=6\n",
      "5 fold done for k=6\n",
      "6 fold done for k=6\n",
      "7 fold done for k=6\n",
      "8 fold done for k=6\n",
      "9 fold done for k=6\n",
      "The validation accuracy for k=6 is 55.769%\n",
      "0 fold done for k=7\n",
      "1 fold done for k=7\n",
      "2 fold done for k=7\n",
      "3 fold done for k=7\n",
      "4 fold done for k=7\n",
      "5 fold done for k=7\n",
      "6 fold done for k=7\n",
      "7 fold done for k=7\n",
      "8 fold done for k=7\n",
      "9 fold done for k=7\n",
      "The validation accuracy for k=7 is 52.244%\n",
      "0 fold done for k=8\n",
      "1 fold done for k=8\n",
      "2 fold done for k=8\n",
      "3 fold done for k=8\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "for k in range(1, 10):\n",
    "    correct = 0\n",
    "    for i in range(10):\n",
    "        validate_indices_low = math.floor(i / 10 * len(data_train))\n",
    "        validate_indices_high = math.floor((i + 1) / 10 * len(data_train))\n",
    "        data_validate = data_train.iloc[range(validate_indices_low, \n",
    "                                              validate_indices_high)]\n",
    "        data_fit = data_train.iloc[[i for i in range(len(data_train)) \n",
    "                                    if i not in range(validate_indices_low, \n",
    "                                                      validate_indices_high)]]\n",
    "        watch_pred = pd.DataFrame(data_validate['watch'])\n",
    "        watch_pred['pred'] = data_validate.apply(lambda row: predict(data_fit, row.drop('watch'), k), axis=1)\n",
    "        correct += len(watch_pred[watch_pred['watch'] == watch_pred['pred']])\n",
    "        print(f'{i} fold done for k={k}')\n",
    "    accuracy.append(correct / len(data_train))\n",
    "    print(f'The validation accuracy for k={k} is {round(accuracy[k - 1] * 100, 3)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing\n",
    "\n",
    "As can be seen from the output above, the optimal value of k on the training/validation data was $k = 9$. We will finally test the model on the reserved testing data to get a true final accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_k = 9\n",
    "watch_pred = pd.DataFrame(data_test['watch'])\n",
    "watch_pred['pred'] = data_test.apply(lambda row: predict(data_train, row.drop('watch'), final_k), axis=1)\n",
    "correct = len(watch_pred[watch_pred['watch'] == watch_pred['pred']])\n",
    "accuracy = correct / len(data_test)\n",
    "print(f'The accuracy on the testing data for k={final_k} is {round(accuracy * 100, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we end with a thoroughly dissapointing final accuracy of 50.962% meaning we should probably just guess instead!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Using Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2718) # Euler\n",
    "training_frac = 0.8\n",
    "testing_frac = 0.2\n",
    "indices_train = random.sample([i for i in range(len(data))], \n",
    "                              math.floor(training_frac * len(data)))\n",
    "indices_test = random.sample([i for i in range(len(data)) if i not in indices_train], \n",
    "                             math.floor(testing_frac * len(data)))\n",
    "data_train = data.iloc[indices_train].reset_index()\n",
    "data_test = data.iloc[indices_test].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "for k in range(1, 30):\n",
    "    # By passing distance we give closer points a higher weight\n",
    "    # I have set the algorithm to brute meaning that the distance to \n",
    "    # all points will be checked. As I have above\n",
    "    model = KNeighborsClassifier(k, weights='distance',algorithm='brute')\n",
    "    correct = 0\n",
    "    for i in range(10):\n",
    "        validate_indices_low = math.floor(i / 10 * len(data_train))\n",
    "        validate_indices_high = math.floor((i + 1) / 10 * len(data_train))\n",
    "        data_validate = data_train.iloc[range(validate_indices_low, \n",
    "                                              validate_indices_high)]\n",
    "        data_fit = data_train.iloc[[i for i in range(len(data_train)) \n",
    "                                    if i not in range(validate_indices_low, \n",
    "                                                      validate_indices_high)]]\n",
    "        watch_pred = pd.DataFrame(data_validate['watch'])\n",
    "        model.fit(data_fit.drop('watch', axis=1), data_fit['watch'])\n",
    "        watch_pred['pred'] = model.predict(data_validate.drop('watch', axis=1))\n",
    "        correct += len(watch_pred[watch_pred['watch'] == watch_pred['pred']])\n",
    "    accuracy.append(correct / len(data_train))\n",
    "    print(f'The validation accuracy for k={k} is {round(accuracy[k - 1] * 100, 3)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_k = 2\n",
    "# Same parameters as above\n",
    "model = KNeighborsClassifier(final_k, weights='distance', algorithm='brute')\n",
    "watch_pred = pd.DataFrame(data_test['watch'])\n",
    "# This time we fit on all the training data\n",
    "model.fit(data_train.drop('watch', axis=1), data_train['watch'])\n",
    "# Predict on the remaining, unseen 20% of testing data\n",
    "watch_pred['pred'] = model.predict(data_test.drop('watch', axis=1))\n",
    "correct = len(watch_pred[watch_pred['watch'] == watch_pred['pred']])\n",
    "accuracy = correct / len(data_test)\n",
    "print(f'The accuracy on the testing data for k={final_k} is {round(accuracy * 100, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above show that the k-Nearest Neighbors classifier is not performing well even for large values of k. This indicates that the predictor variables are not doing a good job of predicting! It is back to the drawing board for the model. Perhaps different variables will work better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
